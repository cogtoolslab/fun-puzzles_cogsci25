{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<a name=\"top\"></a>\n",
            "\n",
            "# Identify and upload stimuli sequences to Mongo\n",
            "\n",
            "## Contents:\n",
            "* [Import Packages + Set up Paths](#import)\n",
            "\n",
            "* [Compute & summarize puzzle metrics](#compute)  \n",
            "\n",
            "* [Identify experimental puzzles](#identify)  \n",
            "\n",
            "* [Shuffle and counterbalance experiment stimuli sequences](#shuffle)  \n",
            "\n",
            "* [Push stimuli sequences to Mongo](#mongo)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os, sys\n",
            "import pymongo as pm\n",
            "import pandas as pd\n",
            "import ast\n",
            "import numpy as np\n",
            "from scipy.stats import skew, kurtosis\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "sns.set_context('talk')\n",
            "sns.set_style('white')\n",
            "\n",
            "import random\n",
            "import itertools\n",
            "import json\n",
            "\n",
            "from operator import itemgetter\n",
            "from collections import Counter\n",
            "\n",
            "from IPython.display import clear_output\n",
            "from pprint import pprint\n",
            "\n",
            "# mongo parameters\n",
            "project_name = 'fun-puzzles'\n",
            "experiment_name = 'fun-puzzles-exp1'\n",
            "iterationName = 'production2' # pilot1_debug\n",
            "mongo_collection_name = experiment_name #'fun-puzzles-debug' # this should match experiment name\n",
            "\n",
            "# repo directory and file hierarchy\n",
            "proj_dir =  os.path.abspath('../..')\n",
            "stimuli_dir = os.getcwd()\n",
            "output_dir = os.path.join(stimuli_dir, experiment_name)\n",
            "\n",
            "dumpjson = False ## do we want to save the stimuli json?\n",
            "write = False ## do we ACTUALLY want to write to mongo?\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# <a name=\"import\"></a> import csv of novice levels([^](#top))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Some settings + set up paths"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Load level identifiers\n",
            "Load in manually identified collections that are recommended for novices (e.g., from online forums, from author descriptions)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "novice_levels = pd.read_csv(\"sokoban-for-novices_metadata.csv\",\n",
            "                            converters={\"layout\": ast.literal_eval,\n",
            "                                        \"top_solutions\": ast.literal_eval})\n",
            "novice_levels['sokobanonline__top_solutions'] = novice_levels['sokobanonline__top_solutions'].apply(ast.literal_eval)\n",
            "novice_levels.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# <a name=\"compute\"></a> Compute difficulty and enjoyment metrics([^](#top))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The information from sokobanonline allows computing three sets of metrics for each puzzle: \n",
            "\n",
            "- Visual features\n",
            "- Difficulty\n",
            "- Enjoyment "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Visual features: \n",
            "\n",
            "- **area**: Rectangular area occupied by puzzle (in number of tiles)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# approx area of puzzle\n",
            "novice_levels[\"level_area\"] = novice_levels[\"level_width\"]*novice_levels[\"level_height\"]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Gleaned Difficulty:\n",
            "\n",
            "- **shortest_solution**: Step length of shortest solution\n",
            "- **solve_rate**: Number completed / attempted\n",
            "- From top solutions table (i.e., number of completions for each of top 10 shortest solution lengths)\n",
            "    - **Kurtosis**: How concentrated vs. wide is the distribution? Does everyone find the same best solution?\n",
            "    - **Skew**: How skewed is this distribution? Left skew suggests many people found the best solution. Alternatives are everyone finds a non-optimal solution, or perhaps there is a bimodal distribution\n",
            "\n",
            "Note: **High kurtosis indicates**:\n",
            "- Sharp peakedness in the distributionâ€™s center.\n",
            "- More values concentrated around the mean than normal distribution.\n",
            "- Heavier tails because of a higher concentration of extreme values or outliers in tails.\n",
            "- Greater likelihood of extreme events."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Step length of shortest solution\n",
            "novice_levels[\"sokobanonline__shortest\"] = novice_levels[\"sokobanonline__top_solutions\"].apply(\n",
            "    lambda x: x[0]['steps'] if isinstance(x, list) and len(x) > 0 else None\n",
            ")\n",
            "# ratio completed/attempted \n",
            "novice_levels[\"sokobanonline__solve_rate\"] = novice_levels[\"sokobanonline__num_solved\"]/ novice_levels[\"sokobanonline__num_played\"]\n",
            "## record of every attempt that made it to top 10 solutions \n",
            "novice_levels[\"sokobanonline__top_solutions_flattened\"] = novice_levels[\"sokobanonline__top_solutions\"].apply(\n",
            "    lambda x: [step for a in x for step in [a['steps']]* a['num_players']] if isinstance(x, list) and len(x) > 0 else None\n",
            ")\n",
            "## Kurtosis, skewness: density curve of height (num solved), x-axis (number of steps)\n",
            "# novice_levels[\"sokobanonline___skewness\"] = novice_levels[\"sokobanonline__top_solutions_flattened\"].apply(lambda x: abs(skew(x, bias=True)))\n",
            "# novice_levels[\"sokobanonline___kurtosis\"] = novice_levels[\"sokobanonline__top_solutions_flattened\"].apply(lambda x: kurtosis(x, bias=True))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "difficulty_columns = [\"level_area\", \"sokobanonline__shortest_solution\", \"sokobanonline__solve_rate\"]\n",
            "\n",
            "# univariate histograms\n",
            "fig, ax = plt.subplots(1,len(difficulty_columns), figsize=(15, 3))\n",
            "\n",
            "for i, ax in enumerate(ax.flatten()):\n",
            "    sns.histplot(novice_levels[difficulty_columns[i]],\n",
            "                                  stat='percent', ax=ax,)\n",
            "    \n",
            "fig.suptitle('Gleaned difficulty metrics')\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "## What do top 10 solutions give us? \n",
            "level_ids = random.sample(range(len(novice_levels)), 8)\n",
            "\n",
            "fig, ax = plt.subplots(2,4, figsize=(12, 6))\n",
            "\n",
            "for i, ax in enumerate(ax.flatten()):\n",
            "    sns.histplot(novice_levels.iloc[level_ids[i]].sokobanonline__top_solutions_flattened,\n",
            "                 bins=10, discrete=True,\n",
            "                 ax=ax)\n",
            "    ax.set_title(\"{}_{}\".format(novice_levels.collection_name[level_ids[i]][0:7], str(novice_levels.level_name[i])))\n",
            "    ax.set_xlabel(\"steps taken\")\n",
            "    ax.set_xticks([min(novice_levels.iloc[level_ids[i]].sokobanonline__top_solutions_flattened),\n",
            "                       max(novice_levels.iloc[level_ids[i]].sokobanonline__top_solutions_flattened)])\n",
            "    \n",
            "fig.suptitle(\"Frequency distribution of top 10 solutions per puzzle\")\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "correlation_matrix = novice_levels[difficulty_columns].corr()\n",
            "\n",
            "# Create a heatmap for the correlation matrix\n",
            "plt.figure(figsize=(8, 6))\n",
            "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
            "plt.title(\"Gleaned difficulty metrics - Correlations\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Scatterplot matrix with regression lines\n",
            "plt.figure(figsize=(8, 6))\n",
            "sns.pairplot(\n",
            "    novice_levels[difficulty_columns],\n",
            "    kind=\"reg\",  # Adds regression lines to scatterplots\n",
            "    diag_kind=\"kde\",  # Kernel density estimation for the diagonal\n",
            "    plot_kws={'line_kws':{'color':'red'}}\n",
            ")\n",
            "plt.suptitle('Gleaned difficulty metrics')\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Gleaned Enjoyment: \n",
            "\n",
            "- **reaction_rate**: total_reactions/num_attempted \n",
            "- **like_rate**: num_liked/num_attempted \n",
            "- **dislike rate**: num_disliked/num_attempted\n",
            "- **like_perc**: num_liked / total_reactions\n",
            "- **dislike_perc**: num_disliked / total_reactions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Feelings: total_reactions/num_attempted\n",
            "# ratio completed/attempted \n",
            "novice_levels[\"sokobanonline__reaction_rate\"] = (novice_levels[\"sokobanonline__likes\"]+novice_levels[\"sokobanonline__dislikes\"])/ novice_levels[\"sokobanonline__num_played\"]\n",
            "# Like Rate: num_liked/num_attempted\n",
            "novice_levels[\"sokobanonline__likes_rate\"] = novice_levels[\"sokobanonline__likes\"]/ novice_levels[\"sokobanonline__num_played\"]\n",
            "# Like Score: num_liked / total reactions\n",
            "novice_levels[\"sokobanonline__likes_perc\"] = novice_levels[\"sokobanonline__likes\"]/(novice_levels[\"sokobanonline__likes\"]+ novice_levels[\"sokobanonline__dislikes\"])\n",
            "# Dislike Rate: num_disliked/num_attempted\n",
            "novice_levels[\"sokobanonline__dislikes_rate\"] = novice_levels[\"sokobanonline__dislikes\"]/ novice_levels[\"sokobanonline__num_played\"]\n",
            "# Like Score: num_liked / total reactions\n",
            "novice_levels[\"sokobanonline__dislikes_perc\"] = novice_levels[\"sokobanonline__dislikes\"]/(novice_levels[\"sokobanonline__likes\"]+ novice_levels[\"sokobanonline__dislikes\"])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "enjoyment_columns = [\"sokobanonline__reaction_rate\", \n",
            "                     \"sokobanonline__likes_rate\", \"sokobanonline__likes_perc\", \n",
            "                     \"sokobanonline__dislikes_rate\", \"sokobanonline__dislikes_perc\"]\n",
            "\n",
            "# univariate histograms\n",
            "fig, ax = plt.subplots(1,len(enjoyment_columns), figsize=(15, 3))\n",
            "\n",
            "for i, ax in enumerate(ax.flatten()):\n",
            "    this_var = enjoyment_columns[i]\n",
            "    sns.histplot(novice_levels[this_var],\n",
            "                 stat='percent',\n",
            "                 ax=ax)\n",
            "    ax.set_xlabel(this_var.split(\"__\")[-1])\n",
            "    \n",
            "fig.suptitle('Gleaned enjoyment metrics')\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "correlation_matrix = novice_levels[enjoyment_columns].corr()\n",
            "\n",
            "# Create a heatmap for the correlation matrix\n",
            "plt.figure(figsize=(8, 6))\n",
            "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
            "plt.title(\"Gleaned enjoyment metrics - Correlations\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# exclude outlier of dislike ratio\n",
            "df = novice_levels.query('sokobanonline__dislikes_rate < .03')[enjoyment_columns]\n",
            "plt.figure(figsize=(8, 6))\n",
            "# # Scatterplot matrix with regression lines\n",
            "sns.pairplot(\n",
            "    df,\n",
            "    kind=\"reg\",  # Adds regression lines to scatterplots\n",
            "    diag_kind=\"kde\",  # Kernel density estimation for the diagonal\n",
            "    plot_kws={'line_kws':{'color':'red'}}\n",
            ")\n",
            "plt.suptitle(\"Gleaned enjoyment metrics - correlations\")\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## compare / correlations"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Enjoyment vs. Difficulty -- novice collections\n",
            "sns.pairplot(\n",
            "    novice_levels,\n",
            "    x_vars=difficulty_columns,\n",
            "    y_vars=enjoyment_columns,\n",
            "    hue=\"collection_name\",\n",
            "    plot_kws={'alpha': 0.5}\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Determine the number of rows and columns for the subplot grid\n",
            "num_rows = len(enjoyment_columns)\n",
            "num_cols = len(difficulty_columns)\n",
            "# Create a figure and a grid of subplots\n",
            "fig, axes = plt.subplots(num_cols, num_rows, figsize=(5 * num_cols, 3 * num_rows))\n",
            "\n",
            "# Iterate over each pair of columns and create a scatter plot with a regression line\n",
            "for i, col1 in enumerate(difficulty_columns):\n",
            "    for j, col2 in enumerate(enjoyment_columns):\n",
            "        ax = axes[i, j]\n",
            "        sns.regplot(x=novice_levels[col1], y=novice_levels[col2], ax=ax, ci=None, line_kws={\"color\": \"red\"})\n",
            "        pearson_text = f\"Pearson {r'$\\rho$'} = {novice_levels[col1].corr(df[col2]):.2f}\"\n",
            "        spearman_text = f\"Spearman {r'$\\rho$'} = {novice_levels[col1].corr(df[col2], method='spearman'):.2f}\"\n",
            "        ax.set_title(pearson_text + \"\\n\" + spearman_text)\n",
            "        # ax.label_outer()  # Only show outer labels and tick labels\n",
            "        \n",
            "\n",
            "# Add column labels at the top\n",
            "# for ax, col in zip(axes[-1], enjoyment_columns):\n",
            "#     ax.annotate(col, xy=(0.5, -0.1), xytext=(0, -5),\n",
            "#                 xycoords='axes fraction', textcoords='offset points',\n",
            "#                 ha='center', va='top', fontsize=14, fontweight='bold')\n",
            "\n",
            "# Add row labels on the left\n",
            "# for ax, row in zip(axes[:,0], difficulty_columns):\n",
            "#     ax.annotate(row, xy=(-0.1, 0.5), xytext=(-ax.yaxis.labelpad - 5, 0),\n",
            "#                 xycoords='axes fraction', textcoords='offset points',\n",
            "#                 ha='right', va='center', fontsize=14, fontweight='bold', rotation=90)\n",
            "\n",
            "plt.suptitle(\"Enjoyment vs. Difficulty -- novice collections\")\n",
            "# Adjust layout to prevent overlap\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "selected_col = enjoyment_columns + difficulty_columns\n",
            "correlation_matrix = novice_levels[selected_col].corr()\n",
            "\n",
            "# Create a heatmap for the correlation matrix\n",
            "plt.figure(figsize=(10, 10))\n",
            "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
            "plt.title(\"Correlation Matrix Heatmap\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# <a name=\"identify\"></a> Identify 24 levels([^](#top))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Filter for not too complex or hard"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "First, we identify levels with the following features:\n",
            "- Width and height is between 5 to 9 tiles (inclusive)\n",
            "- 3 boxes\n",
            "- at least 100 attempts in corpus\n",
            "- at least 50% solved\n",
            "- max 99 moves"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "novice_3box_df = (\n",
            "    novice_levels\n",
            "    .query('5 < level_width < 10')\n",
            "    .query('5 < level_height < 10')\n",
            "    .query('num_boxes == 3')\n",
            "    .query('100 <= sokobanonline__num_played')\n",
            "    .query('100 > sokobanonline__shortest_solution')\n",
            "    .query('sokobanonline__solve_rate > 0.5') # at least 50% solved\n",
            ")\n",
            "\n",
            "print(f\"Filtered to {novice_3box_df.shape[0]} levels\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Define 2x2x2 parameters"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Next we compute three features, and produce 3 bins per feature\n",
            "- enjoyment: (#likes - #dislikes) / #played\n",
            "- difficulty: #solved / #played\n",
            "- shortest solution found in corpus"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "novice_3box_df = (\n",
            "    novice_3box_df\n",
            "    .assign(enjoyment_cat = pd.qcut(novice_3box_df['sokobanonline__likes_rate'], q=2, labels=['low','high']),\n",
            "         difficulty_cat = pd.qcut(novice_3box_df['sokobanonline__solve_rate'], q=2, labels=['hard', 'easy']),\n",
            "         shortestPath_cat = pd.qcut(novice_3box_df['sokobanonline__shortest_solution'], q=2, labels=['short', 'long']))\n",
            ")\n",
            "\n",
            "# export\n",
            "novice_3box_df.to_csv(os.path.join(stimuli_dir, \"small-3box_puzzles.csv\"),index=False)\n",
            "\n",
            "# tabulate\n",
            "print(pd.crosstab([novice_3box_df[\"shortestPath_cat\"], novice_3box_df[\"difficulty_cat\"]], novice_3box_df[\"enjoyment_cat\"]))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Sample 3 levels for each 2x2x2 cell"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "exp1_levels = (\n",
            "    novice_3box_df\n",
            "    .groupby(['shortestPath_cat', 'difficulty_cat', 'enjoyment_cat'])\n",
            "    .sample(3, random_state=40)\n",
            "    .filter(['author_name','collection_name', 'level_name', 'layout','level_width','level_height',\n",
            "           'sokobanonline__likes_rate','sokobanonline__solve_rate','sokobanonline__shortest_solution',\n",
            "           'enjoyment_cat', 'difficulty_cat', 'shortestPath_cat'])\n",
            "    .reset_index(drop=True))\n",
            "\n",
            "exp1_levels['stimuli_set'] = np.tile(['A','B','C'], int(len(exp1_levels)/3))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.options.display.float_format = '{:.4f}'.format\n",
            "\n",
            "# Check\n",
            "(exp1_levels\n",
            " .groupby('stimuli_set')\n",
            " .agg({'sokobanonline__solve_rate': ['min', 'median', 'max'],\n",
            "       'sokobanonline__likes_rate': ['min', 'median', 'max'],\n",
            "       'sokobanonline__shortest_solution': ['min', 'median', 'max']}))\n",
            "\n",
            "# Check\n",
            "pd.pivot_table(exp1_levels, index=['difficulty_cat', 'enjoyment_cat', 'shortestPath_cat'], columns='stimuli_set', values='layout',aggfunc='count')\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Save levels"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_boxes(layout):\n",
            "    # print(get_boxes(original_json['SokobanLevels']['LevelCollection']['Level'][1]['L']))\n",
            "    all_boxes = []\n",
            "    for y, row in enumerate(layout):\n",
            "        for x, obj in enumerate(row):\n",
            "            if obj == \"$\" or obj == '*':  # $ if on floor, * if on goal\n",
            "                all_boxes.append({'x': x, 'y': y, 'state': obj})\n",
            "    return (all_boxes)\n",
            "\n",
            "def get_start_position(layout):\n",
            "    # print(get_start_position(original_json['SokobanLevels']['LevelCollection']['Level'][0]['L']))\n",
            "    for y, row in enumerate(layout):\n",
            "        for x, symbol in enumerate(row):\n",
            "            if symbol == '@' or symbol == '+':    # @ if on floor, + if on goal\n",
            "                return {\"x\": x, \"y\": y}\n",
            "    return None\n",
            "\n",
            "exp1_levels['boxes'] = exp1_levels['layout'].apply(get_boxes)\n",
            "exp1_levels['start_position'] = exp1_levels['layout'].apply(get_start_position)\n",
            "\n",
            "## inspect first few rows of metadata object\n",
            "exp1_levels.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "exp1_levels = exp1_levels.reset_index(names=\"puzzle_id\")\n",
            "## tell us some useful information\n",
            "print(f'We have {len(exp1_levels)} stimuli represented in our metadata dataframe.')\n",
            "print(' ')\n",
            "print(f'These are the columns in this dataframe: {exp1_levels.columns}.')\n",
            "\n",
            "# Export\n",
            "exp1_levels.to_csv(os.path.join(output_dir, f'{iterationName}_puzzles-test.csv'),index=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# <a name=\"shuffle\"></a> Shuffle and counterbalance experiment stimuli sequences([^](#top))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We generally take one of two approaches when inserting our metadata into mongo:\n",
            "\n",
            "- **DIRECT INSERTION**: direct insertion of individual trials (a.k.a. 'items') as individual records in mongo. This option is reasonable when it doesn't matter which stimulus a participant gets on any given trial, e.g., if we simply plan to annotate a bunch of stimuli.\n",
            "- **BATCHING**: grouping metadata from multiple trials into a batch and then inserting these complete batches into mongo. This option is reasonable when we want to control which exact combination of stimuli a specific participant gets.\n",
            "\n",
            "For this study, we use **BATCHING** since we need to counterbalance across pretest, test, and posttest trials."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df = (exp1_levels[['stimuli_set', 'collection_name', 'level_name',\n",
            "                  'level_width', 'level_height', 'layout', 'start_position', 'boxes']]\n",
            "                  .rename(columns={'level_width': 'width', 'level_height': 'height'}))\n",
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Sample comparison pairs\n",
            "\n",
            "For each set, make 20 sessions. Each session has 8 comparison pairs.\n",
            "each set will be assigned to one of 2 conditions & either pre/post -- so for every 'comparison trial', matched Ns for condition and study phase.\n",
            "\n",
            "20 stimuli matches x 2 conditions x 2 study phase = 80\n",
            "80 x 3 sets = 240 sessions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# sampling and printing functions\n",
            "# \n",
            "def make_comparison_trials(list_of_level_indexes, n_sessions):\n",
            "    sessions = []\n",
            "    # possible_pairs = [(x, y) for i, x in enumerate(list_of_level_indexes) for j, y in enumerate(list_of_level_indexes) if i < j]\n",
            "    # possible_pairs = list(itertools.combinations(list_of_level_indexes, 2))\n",
            "    for i in range(n_sessions):\n",
            "        l1 = [x for x in list_of_level_indexes]\n",
            "        random.shuffle(l1)        \n",
            "        l1.extend(l1[1:])\n",
            "        l1.append(l1[0])\n",
            "        pairs = list(itertools.batched(l1, 2))\n",
            "        trials = []\n",
            "        for pair in pairs:\n",
            "            trials.append(df[df.index.isin(pair)].to_dict('records'))\n",
            "        sessions.append(trials)\n",
            "\n",
            "    # print helpful stuff\n",
            "    print(f\"Generating {n_sessions} sessions of {len(trials)} comparison trials each with {len(pair)} items...\")\n",
            "\n",
            "    # Return the action list of sessions\n",
            "    return(sessions)\n",
            "\n",
            "def count_pairs_in_comparisons(list_of_sessions, print=False):\n",
            "    '''\n",
            "    Given list of sessions, each session containing a list of comparison trials, each trial a list of two levels,\n",
            "    Count the number of comparisons taht each level occurs in\n",
            "    '''    \n",
            "    pairings = []\n",
            "    for sessionN in range(len(list_of_sessions)):\n",
            "        for trialN in range(len(list_of_sessions[sessionN])):\n",
            "            pairings.append([itemgetter(*['collection_name','level_name'])(x) for x in list_of_sessions[sessionN][trialN]])\n",
            "    my_dict = Counter([tuple(i) for i in pairings])\n",
            "    if print: \n",
            "        pprint(my_dict)\n",
            "    return my_dict\n",
            "\n",
            "def count_levels_in_comparisons(list_of_sessions):\n",
            "    '''\n",
            "    Given list of sessions, each session containing a list of comparison trials, each trial a list of two levels,\n",
            "    Count the number of comparisons taht each level occurs in\n",
            "    '''\n",
            "    # Count occurrences of pairs\n",
            "    # Counter([tuple(i) for i in list_of_sessions])\n",
            "    # Count occurrences of each level\n",
            "    flat = list(itertools.chain(*list_of_sessions))\n",
            "    flat_df = pd.concat(list(map(pd.json_normalize, flat)))\n",
            "    print(flat_df.value_counts(['collection_name', 'level_name']))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Set up \n",
            "stim_level_indexes = {\n",
            "    'A' : df[df['stimuli_set']=='A'].index,\n",
            "    'B': df[df['stimuli_set']=='B'].index,\n",
            "    'C': df[df['stimuli_set']=='C'].index\n",
            "    }\n",
            "\n",
            "# Parameters\n",
            "n_sessions = 20 # per condition and counterbalancing\n",
            "n_compare_trials = 8\n",
            "random.seed(42)\n",
            "\n",
            "# Let's make some stimuli\n",
            "stim_comparisons = {}\n",
            "for letter in ['A', 'B', 'C']:\n",
            "    print(\"\\nCOMPARISONS FOR SET \" + letter)\n",
            "    stim_comparisons[letter] = make_comparison_trials(stim_level_indexes[letter], n_sessions)\n",
            "    count_levels_in_comparisons(stim_comparisons[letter])\n",
            "    count_pairs_in_comparisons(stim_comparisons[letter], False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# sanity check\n",
            "print(f\"Comparison A has {len(stim_comparisons['A'])} sessions with {len(stim_comparisons['A'][0])} trials, each contrasting {len(stim_comparisons['A'][0][0])} levels\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Assign condition and counterbalance exp phases"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "J = []\n",
            "for [a, b, c] in itertools.permutations(['A', 'B', 'C']):\n",
            "  for condition in ['difficult', 'enjoyable']: \n",
            "    print(condition, a, b, c)\n",
            "    for session_id in range(20):\n",
            "      J.append({\"condition\": condition,\n",
            "        \"stimuli_set_order\": a + b + c,\n",
            "        \"stims\": {\n",
            "          \"stimuli_test\": df[df.index.isin(stim_level_indexes[a])].to_dict('records'),\n",
            "          \"stimuli_compare1\": stim_comparisons[b][session_id],\n",
            "          \"stimuli_compare2\": stim_comparisons[c][session_id]\n",
            "      }})\n",
            "    # print(f\"Test: {len(blah['stims']['stimuli_test'])}; Pretest: {len(blah['stims']['stimuli_compare1'])}; Posttest: {len(blah['stims']['stimuli_compare2'])}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Double check before mongo"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "## optionally, save out meta to meta.js file\n",
            "if dumpjson:\n",
            "    with open(os.path.join(output_dir, f'{iterationName}_all-stimuli-records.json'), 'w') as fout:\n",
            "        json.dump(J, fout)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "## let's look at a single record before inserting it into mongo\n",
            "single_record = J[0]\n",
            "single_record"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# <a name=\"mongo\"></a> Push To Mongo ([^](#top))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Connect to Mongo\n",
            "\n",
            "Note: This command for \"establishing an SSH tunnel\" is also known as \"remote port forwarding.\"\n",
            "\n",
            "You'll need to re-run this command basically every time your internet connection resets. A clue that this has happened is that you'll see Broken pipe appear in your terminal. No worries, just do it again!"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "vscode": {
               "languageId": "shellscript"
            }
         },
         "outputs": [],
         "source": [
            "! ssh -fNL 27017:127.0.0.1:27017 junyichu@cogtoolslab.org"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# set vars\n",
            "auth = pd.read_json(os.path.join(proj_dir,'auth.json'), typ='series') # this auth.json file contains the password\n",
            "pswd = auth.password\n",
            "user = auth.user\n",
            "host = 'cogtoolslab.org'\n",
            "\n",
            "# have to fix this to be able to analyze from local\n",
            "import socket\n",
            "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
            "db = conn['stimuli'] # for data, it's experimentName\n",
            "coll = db[mongo_collection_name] #FIXME check me everytime."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Insert each session as a record into mongoDB"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "with open(os.path.join(output_dir, f'{iterationName}_all-stimuli-records.json'), 'r') as f:\n",
            "    json_string = f.read() \n",
            "    data = json.loads(json_string)\n",
            "    \n",
            "type(data)\n",
            "data[1].keys()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "num_existing_records = coll.estimated_document_count() ## how many existing records are there?\n",
            "print(num_existing_records)\n",
            "\n",
            "if write:\n",
            "    ## first drop existing records from this collection only if it is NOT empty (be careful!)\n",
            "    if num_existing_records>0:    \n",
            "        db.drop_collection(mongo_collection_name)\n",
            "        print('Dropped existing records from this collection.')\n",
            "\n",
            "    ## ok, now let's actually add our metadata to the database\n",
            "    for (i,m) in enumerate(J):\n",
            "        coll.insert_one(m)\n",
            "        print(f'{i+1} of {len(J)}| Inserting condition {m[\"condition\"]}')\n",
            "        clear_output(wait=True)\n",
            "\n",
            "print('Done inserting records into mongo!')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "## check collection to see what records look like\n",
            "coll.find_one()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "## how many records are there in this collection?\n",
            "coll.estimated_document_count()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.3"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
